{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning\n",
    "\n",
    "**Deep learning is a subset of machine learning in artificial intelligence (AI) that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Neural Network\n",
    "\n",
    "**A neural network is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates. In this sense, neural networks refer to systems of neurons, either organic or artificial in nature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧠 Introduction to Neural Networks: \n",
    "\n",
    "A **Neural Network** is a computational model inspired by the way biological neural networks in the human brain process information.\n",
    "\n",
    "---\n",
    "\n",
    "## 📘 Step 1: What is a Neural Network?\n",
    "\n",
    "A **neural network** is made up of layers of nodes (also called neurons). Each node mimics a biological neuron and performs simple computations.\n",
    "\n",
    "### Structure:\n",
    "- **Input Layer**: Receives the data (e.g., features).\n",
    "- **Hidden Layer(s)**: Performs intermediate processing.\n",
    "- **Output Layer**: Produces the final prediction/output.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔢 Step 2: Inputs and Weights\n",
    "\n",
    "Each input is assigned a **weight** that reflects its importance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Where:\n",
    "- `xi` = input features\n",
    "- `wi` = corresponding weights\n",
    "- `b` = bias (helps with shifting the activation)\n",
    "- `z` = weighted sum (net input)\n",
    "\n",
    "---\n",
    "\n",
    "## 🧮 Step 3: Activation Function\n",
    "\n",
    "After computing the weighted sum, the result is passed through an **activation function**, which introduces non-linearity.\n",
    "\n",
    "### Common Activation Functions:\n",
    "- **Sigmoid**:  \n",
    "  `sigmoid(z) = 1 / (1 + e^(-z))`\n",
    "- **ReLU (Rectified Linear Unit)**:  \n",
    "  `ReLU(z) = max(0, z)`\n",
    "- **Tanh**:  \n",
    "  `tanh(z) = (e^z - e^(-z)) / (e^z + e^(-z))`\n",
    "\n",
    "These functions allow the network to learn complex patterns.\n",
    "\n",
    "$$z = w_1 * x_1 + w_2 * x_2 + ... + w_n * x_n + b$$\n",
    "\n",
    "---\n",
    "\n",
    "## 📤 Step 4: Forward Propagation\n",
    "\n",
    "This is the process of sending input data through the network:\n",
    "\n",
    "1. Multiply inputs by weights\n",
    "2. Add bias\n",
    "3. Apply activation function\n",
    "4. Pass to next layer (or output)\n",
    "\n",
    "This gives the predicted output.\n",
    "\n",
    "---\n",
    "\n",
    "## 📉 Step 5: Loss Function\n",
    "\n",
    "We measure the difference between the **predicted output** and the **actual output** using a **loss function**.\n",
    "\n",
    "### Examples:\n",
    "- **Mean Squared Error (MSE)** for regression\n",
    "- **Binary Cross-Entropy** for binary classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scgoo\\AppData\\Local\\Temp\\ipykernel_10884\\2839917149.py:9: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
      "  from IPython.core.display import display, Image\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy.random import randn\n",
    "import random\n",
    "from IPython.core.display import display, Image\n",
    "from string import Template\n",
    "import IPython.display\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate how a neural network:\n",
    "\n",
    "- Initializes weights\n",
    "\n",
    "- Applies an activation function (sigmoid)\n",
    "\n",
    "- Learns through training (adjusting weights based on error)\n",
    "\n",
    "- Makes predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class named NeuralNetwork\n",
    "class NeuralNetwork():\n",
    "    \n",
    "    # Constructor method to initialize the neural network\n",
    "    def __init__(self):\n",
    "        # Set a fixed random seed for reproducibility of random numbers\n",
    "        np.random.seed(1)\n",
    "        # Initialize synaptic weights randomly with values between -1 and 1 for a 3-input neuron\n",
    "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
    "    \n",
    "    # Define the sigmoid activation function\n",
    "    def sigmoid(self, x):\n",
    "        # Returns the output of the sigmoid function\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    # Define the derivative of the sigmoid function\n",
    "    def sigmoid_derivative(self, x):\n",
    "        # This is an incorrect derivative; the correct one is: x * (1 - x)\n",
    "        # This version is non-standard but may be used to test custom behavior\n",
    "        return x / (1 + x)\n",
    "    \n",
    "    # Method to train the neural network\n",
    "    def train(self, training_inputs, training_outputs, training_iterations):\n",
    "        # Loop through the training process for a specified number of iterations\n",
    "        for itr in range(training_iterations):\n",
    "            # Think (forward pass) with the current weights\n",
    "            output = self.think(training_inputs)\n",
    "            # Calculate the error (difference between actual and predicted)\n",
    "            error = training_outputs - output\n",
    "            # Adjust weights using gradient descent-like update rule\n",
    "            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
    "            # Update the synaptic weights\n",
    "            self.synaptic_weights += adjustments\n",
    "    \n",
    "    # Method to make a prediction (forward pass)\n",
    "    def think(self, inputs):\n",
    "        # Convert inputs to float to ensure correct calculations\n",
    "        inputs = inputs.astype(float)\n",
    "        # Calculate the output by applying the sigmoid to the dot product of inputs and weights\n",
    "        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random synaptic weights: \n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n"
     ]
    }
   ],
   "source": [
    "# This block ensures the following code runs only if this script is executed directly,\n",
    "# not if it's imported as a module in another script.\n",
    "if __name__ == \"__main__\":\n",
    "    # Your code here, indented properly inside this block\n",
    "    neural_network = NeuralNetwork()\n",
    "    print(\"Random synaptic weights: \")\n",
    "    print(neural_network.synaptic_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define the training input dataset (4 examples with 3 input features each)\n",
    "training_inputs = np.array([[0, 0, 1],\n",
    "                                [1, 1, 1],\n",
    "                                [1, 0, 1],\n",
    "                                [0, 1, 1]])\n",
    "    \n",
    "# Define the corresponding outputs for training (column vector)\n",
    "training_outputs = np.array([[0, 1, 1, 0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synaptic weights after training: \n",
      "[[13.38883717]\n",
      " [-0.18998542]\n",
      " [-4.49621121]]\n",
      "New situation: input data =  0 1 1\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network with the input/output pairs for 10,000 iterations\n",
    "neural_network.train(training_inputs, training_outputs, 10000)\n",
    "    \n",
    "# Print synaptic weights after training\n",
    "print(\"Synaptic weights after training: \")\n",
    "print(neural_network.synaptic_weights)\n",
    "    \n",
    "# Define new input values (can also be collected using input(), but here hard-coded)\n",
    "A = 0\n",
    "B = 1\n",
    "C = 1\n",
    "# Print the new situation inputs\n",
    "print(\"New situation: input data = \", A, B, C)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output data: \n",
      "[0.00913743]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction for the new input and print the result\n",
    "print(\"Output data: \")\n",
    "print(neural_network.think(np.array([A, B, C])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Neural Network From Scratch on Breast Cancer Dataset (NumPy Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 💡 Dataset: Breast Cancer Wisconsin Dataset\n",
    "\n",
    "- Source: `sklearn.datasets.load_breast_cancer()`\n",
    "\n",
    "- Task: Predict whether a tumor is malignant (1) or benign (0) based on features like radius, texture, and area.\n",
    "\n",
    "- Features: 30 numerical features.\n",
    "\n",
    "- Goal: Binary classification (1 = malignant, 0 = benign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ Step 1: Import Required Libraries and Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data         # Features (shape: 569 x 30)\n",
    "y = data.target       # Labels (0 = benign, 1 = malignant)\n",
    "\n",
    "# Normalize the feature data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape y to a column vector\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🧠 Step 2: Define the Neural Network Class (Single-Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        np.random.seed(1)\n",
    "        # Initialize weights randomly between -1 and 1\n",
    "        self.synaptic_weights = 2 * np.random.random((input_size, 1)) - 1\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        # Correct sigmoid derivative\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def train(self, X, y, iterations):\n",
    "        for i in range(iterations):\n",
    "            output = self.think(X)\n",
    "            error = y - output\n",
    "            adjustments = np.dot(X.T, error * self.sigmoid_derivative(output))\n",
    "            self.synaptic_weights += adjustments\n",
    "\n",
    "    def think(self, inputs):\n",
    "        return self.sigmoid(np.dot(inputs, self.synaptic_weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🏋️ Step 3: Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network with 30 input features\n",
    "nn = NeuralNetwork(input_size=X_train.shape[1])\n",
    "\n",
    "# Train the network\n",
    "nn.train(X_train, y_train, iterations=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📊 Step 4: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = nn.think(X_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = np.mean(predicted_classes == y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🧪 Step 5: Predict for a New Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction (probability): 8.276693989812255e-136\n",
      "Predicted class: 0\n",
      "True label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scgoo\\AppData\\Local\\Temp\\ipykernel_10884\\653524960.py:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(\"True label:\", int(sample_label))\n"
     ]
    }
   ],
   "source": [
    "# Pick a random patient from test data\n",
    "sample_index = 5\n",
    "sample_input = X_test[sample_index].reshape(1, -1)\n",
    "sample_label = y_test[sample_index]\n",
    "\n",
    "# Predict\n",
    "sample_pred = nn.think(sample_input)\n",
    "print(\"Model Prediction (probability):\", sample_pred[0][0])\n",
    "print(\"Predicted class:\", int(sample_pred[0][0] > 0.5))\n",
    "print(\"True label:\", int(sample_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scgoo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# In-Class Exercise: Applying Logistic Regression for Comparison\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = log.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Summary\n",
    "\n",
    "We built a **basic neural network from scratch using NumPy** and applied it to a real-world dataset: **Breast Cancer Diagnosis**.\n",
    "\n",
    "---\n",
    "\n",
    "🔍 **No TensorFlow or PyTorch used!**\n",
    "\n",
    "---\n",
    "\n",
    "🚀 **You learned how to:**\n",
    "\n",
    "- ✅ Preprocess data  \n",
    "- ✅ Build a perceptron (single-layer neural network)  \n",
    "- ✅ Train the model on real data  \n",
    "- ✅ Predict outcomes and evaluate performance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
