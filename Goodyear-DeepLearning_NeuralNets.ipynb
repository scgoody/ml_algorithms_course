{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9544b33-c149-42f1-a20f-aa02db8ef88c",
   "metadata": {},
   "source": [
    "# Part 3: Deep Learning & Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d4fdf-6c66-4d7c-834a-dba8e852bb29",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Neural networks mimic the human brain to make predictions by identifying underlying relationships in data. Deep learning consists of machine learning techniques that use neural networks to learn complex patterns from data. Keras is a beginner-friendly library for training neural networks using TensorFlow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ebdb07-5a52-4317-878c-69a0005d4589",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "Neural networks are computational models inspired by the human brain, composed of layers of nodes that represent neurons. They mimic the process by which neurons process input information to produce an output using an avtivation function. Adjusting weights minimizes prediction error and maximizes learning power. These consist of input layers that recieve information, hidden layers that perform calculations, output layers that produce the final prediction, weights that set learning parameters, and activation functions and control non-linearity. Advantages are high flexibility, integration with complex non-linear relationships, and ability to work with structured and unstructured data. Disadvantages are the large amount of data required, difficult interpretability, sensitivity to overfitting, and that it is computationally expensive. Use cases include language processing, and image recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82675fc-f24f-4b7e-8eda-1414a79ad120",
   "metadata": {},
   "source": [
    "### Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee0b792f-7d37-4e5c-bce8-c9b3c6809824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# neural network class\n",
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        np.random.seed(1)\n",
    "        # Now uses dynamic input size\n",
    "        self.synaptic_weights = 2 * np.random.random((input_size, 1)) - 1\n",
    "    \n",
    "    #def sigmoid(self, x):\n",
    "        #return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        x = np.clip(x, -500, 500)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x / (1 + x)  # or use x * (1 - x) for standard\n",
    "    \n",
    "    def train(self, training_inputs, training_outputs, training_iterations):\n",
    "        for itr in range(training_iterations):\n",
    "            output = self.think(training_inputs)\n",
    "            error = training_outputs - output\n",
    "            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
    "            self.synaptic_weights += adjustments\n",
    "    \n",
    "    def think(self, inputs):\n",
    "        inputs = inputs.astype(float)\n",
    "        return self.sigmoid(np.dot(inputs, self.synaptic_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d7b91cc-dfec-4793-925e-ceb1102f6559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scgoo\\anaconda3\\envs\\ml-env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "data_path = \"C:/Users/scgoo/OneDrive/Documents/colleges/Jacksonville/Spring 2025/Math 470 - ML Algorithms/githubMath470/Final Project/data/\"\n",
    "train_df = pd.read_csv(data_path + \"mnist_train.csv\")\n",
    "test_df = pd.read_csv(data_path + \"mnist_test.csv\")\n",
    "X_train = train_df.drop(columns=[\"label\"])\n",
    "y_train = train_df[\"label\"].values.reshape(-1, 1)\n",
    "X_test = test_df.drop(columns=[\"label\"], errors='ignore')  \n",
    "y_test = test_df[\"label\"] if \"label\" in test_df.columns else None\n",
    "\n",
    "# encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_train)\n",
    "y_cat = to_categorical(y_encoded)\n",
    "\n",
    "# standardize \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d9d267b-877f-4570-83cb-34302c525673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize neural network from class\n",
    "nn = NeuralNetwork(input_size=X_train_scaled.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ecd0568-4737-4e1c-8b2f-49b007bc85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "nn.train(X_train_scaled, y_train, training_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da44d3ee-a49a-47d3-8225-3d922aab06f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[1 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = nn.think(X_test_scaled)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# output\n",
    "print(\"Predictions:\")\n",
    "print(predicted_classes.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "798de54e-4b7f-42e6-8eee-7588f9b4170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.1250\n",
      "Precision: 0.0247\n",
      "Recall:    0.1250\n",
      "F1 Score:  0.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scgoo\\anaconda3\\envs\\ml-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Predict on test set\n",
    "predictions = nn.think(X_test_scaled)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# If test labels are available\n",
    "y_test = test_df[\"label\"].values.reshape(-1, 1)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, predicted_classes)\n",
    "precision = precision_score(y_test, predicted_classes, average='weighted')\n",
    "recall = recall_score(y_test, predicted_classes, average='weighted')\n",
    "f1 = f1_score(y_test, predicted_classes, average='weighted')\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df3e22-0603-4f20-80b2-3c27ffd87bd4",
   "metadata": {},
   "source": [
    "### Report\n",
    "\n",
    "The [MNIST](https://www.kaggle.com/datasets/oddrationale/mnist-in-csv) data used for this model is from kaggle. This neural network predicts labels based on pixel values where there are 784 pixels. Accuracy of 0.1250 indicates 12.5% of the pridictions are correct. Precision and recall of 0.0247 and 0.1250, respectively, indicate there are many more false positives than false negatives. The f1 score of 0.0412 further highlights the imbalance in false positives and negatives. Overall, this model did not perform with strong predictive power but could be improved with further tuning and/or additional iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8d536-0a71-46f8-a954-2838da6b8a63",
   "metadata": {},
   "source": [
    "## Deep Learning with Keras\n",
    "\n",
    "Keras is a high-level API that works with TensorFlow to simplify building, training, and deploying deep learning models. TensorFlow is an open source platform by Google used for building and deploying machine learning models. Keras works by defining a model, stacking layers, compiling with model.compile(), training with model.fit(), and evaluating with model.evaluate(). Advantages are ease of use, easy integration, built-in GPA support, and high customizability. Disadvantages are the lower-level control that is limited, contraints in flexibility for extremely complex models, and the fundamental knowledge requirement for effective use. Use cases are text generation and autoencoders. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85abd19a-aa85-4c82-ba12-afc2a9b54404",
   "metadata": {},
   "source": [
    "### Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfe4f171-053f-4a8a-b9f8-5d4b628eae10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 validated image filenames belonging to 10 classes.\n",
      "Found 10000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Paths\n",
    "train_dir = data_path + \"keras/train/train\"\n",
    "test_dir = data_path + \"keras/test/test\"\n",
    "labels_csv = data_path + \"keras/trainLabels.csv\"\n",
    "\n",
    "# Read labels\n",
    "labels_df = pd.read_csv(labels_csv)\n",
    "\n",
    "# change filenames to strings\n",
    "labels_df[\"label\"] = labels_df[\"label\"].astype(str)\n",
    "labels_df[\"id\"] = labels_df[\"id\"].astype(str) + \".png\"\n",
    "\n",
    "# for reading images\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=labels_df,\n",
    "    directory=train_dir,\n",
    "    x_col=\"id\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(64, 64),\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\",\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=labels_df,\n",
    "    directory=test_dir,\n",
    "    x_col=\"id\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(64, 64),\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get number of classes\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Build model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5beff6e-7710-4bb5-8a99-91542869fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "val_dir = data_path + \"keras/test/test\"\n",
    "\n",
    "# Load labels \n",
    "labels_df = pd.read_csv(data_path + \"keras/trainLabels.csv\")\n",
    "labels_df[\"id\"] = labels_df[\"id\"].astype(str) + \".png\"\n",
    "label_to_index = {label: idx for idx, label in enumerate(sorted(labels_df[\"label\"].unique()))}\n",
    "labels_df[\"label_int\"] = labels_df[\"label\"].map(label_to_index)\n",
    "\n",
    "# Build lists of file paths and labels from validation data\n",
    "filepaths = [os.path.join(val_dir, fname) for fname in labels_df[\"id\"]]\n",
    "labels = labels_df[\"label_int\"].values\n",
    "\n",
    "# function to load and preprocess the images\n",
    "def process_image(filepath, label):\n",
    "    # Read the file\n",
    "    image = tf.io.read_file(filepath)\n",
    "    # Decode the PNG image. tf.image.decode_image can be used for PNG or JPEG.\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    # Resize image to 64x64 pixels\n",
    "    image = tf.image.resize(image, [64, 64])\n",
    "    # Normalize the image to [0, 1]\n",
    "    image = image / 255.0\n",
    "    return image, label\n",
    "\n",
    "# Create the dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
    "val_dataset = val_dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4517e546-83b0-442a-a4f3-f91e2dadebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 7ms/step\n",
      "Accuracy: 0.0894\n",
      "Precision: 0.059098928862100664\n",
      "Recall: 0.0903860976019655\n",
      "F1 Score: 0.047628329795483294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scgoo\\anaconda3\\envs\\ml-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Load test labels\n",
    "val_df = labels_df.sample(frac=0.2, random_state=42)  \n",
    "\n",
    "# Load images manually\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for _, row in val_df.iterrows():\n",
    "    img_path = os.path.join(train_dir, row[\"id\"]) \n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        img = img / 255.0  \n",
    "        images.append(img)\n",
    "        labels.append(row[\"label\"])\n",
    "\n",
    "X_val = np.array(images)\n",
    "y_val = np.array(labels)\n",
    "\n",
    "# Encode labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "y_val_encoded = lb.fit_transform(y_val)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_val_encoded, axis=1)\n",
    "\n",
    "# compute metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision:\", precision_score(y_true, y_pred, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_true, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599ed89a-1f4f-4e10-88ca-bbc234577742",
   "metadata": {},
   "source": [
    "### Report \n",
    "\n",
    "The [CIFAR-10](https://www.kaggle.com/c/cifar-10) data used for this model is from kaggle. This deep learning model with karas performs object recognition with computer vision. The dataset include 60000 32x32 color images and associated labels stored in a csv file. These labels make evaluation possible. The accuracy of 0.894 indicates that 8.94% of the preditions are correct. Precision and recall of 0.0591 and 0.0904, respectively, indicate there are more false positives than false negatives. The f1 score of 0.0476 speaks to the overall problem with false predictions. Tuning and more iterations are required to determine if this method has potential for strong predicitve power with this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3eeaa6-c9d1-45ef-8088-7ce6e7963cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
